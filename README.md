# TP5 â€” Web Scraping avec Puppeteer (Node.js)

## ğŸ¯ Objectif pÃ©dagogique

Ce TP a pour objectif de vous faire pratiquer **lâ€™utilisation concrÃ¨te dâ€™une bibliothÃ¨que externe** en Node.js : **Puppeteer**.

Ã€ la fin de ce TP, vous saurez :
- utiliser Puppeteer pour lancer un navigateur **headless** (sans interface graphique),
- scraper des pages web rÃ©elles (Wikipedia),
- extraire et nettoyer des donnÃ©es depuis le DOM,
- fusionner plusieurs sources de donnÃ©es,
- exporter des donnÃ©es en **CSV**,
- afficher les rÃ©sultats via un **serveur HTTP Node.js**,
- appliquer les **bonnes pratiques Git / Node.js**.


## Sujet du TP

Vous devez scraper deux pages Wikipedia publiques :

- **Liste des pays par population**  
  https://fr.wikipedia.org/wiki/Liste_des_pays_par_population

- **Liste des capitales du monde**  
  https://fr.wikipedia.org/wiki/Liste_des_capitales_du_monde

Puis :
1. Extraire les donnÃ©es (pays, population, capitales, drapeaux),
2. Nettoyer les donnÃ©es (notes Wikipedia, formats numÃ©riques),
3. Fusionner les sources,
4. GÃ©nÃ©rer un fichier `countries.csv`,
5. Afficher les donnÃ©es dans une page HTML accessible via `/countries`.


## Structure du projet

```
tp5-scraping-puppeteer/
â”œâ”€â”€ app.js
â”œâ”€â”€ package.json
â”œâ”€â”€ package-lock.json
â”œâ”€â”€ .gitignore
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ population.json
â”‚   â”œâ”€â”€ capitals.json
â”‚   â”œâ”€â”€ countries.json
â”‚   â””â”€â”€ countries.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scrape/
â”‚   â”œâ”€â”€ merge/
â”‚   â”œâ”€â”€ export/
â”‚   â””â”€â”€ utils/
â””â”€â”€ server/
```


## PrÃ©requis techniques

### 1. Installer Git
TÃ©lÃ©charger et installer Git :
- https://git-scm.com/downloads

VÃ©rifier lâ€™installation :
```bash
git --version
```


### 2. Installer Node.js (LTS)
TÃ©lÃ©charger Node.js :
- https://nodejs.org (version **LTS recommandÃ©e**)

VÃ©rifier :
```bash
node --version
npm --version
```

---

## Installation du projet

### 1. Cloner le dÃ©pÃ´t Git

```bash
git clone <URL_DU_DEPOT>
cd tp5-scraping-puppeteer
```

### 2. Installer les dÃ©pendances

```bash
npm install
```

Cette commande :
- lit `package.json`
- tÃ©lÃ©charge **Puppeteer** et ses dÃ©pendances
- recrÃ©e automatiquement le dossier `node_modules`


### 3. Lancer le projet

```bash
npm start
```

Selon lâ€™Ã©tat du cache :
- le scraping est exÃ©cutÃ© automatiquement (si nÃ©cessaire),
- les fichiers JSON / CSV sont gÃ©nÃ©rÃ©s,
- le serveur HTTP dÃ©marre.


## AccÃ¨s Ã  lâ€™application

Une fois le serveur lancÃ© :

- Page principale :  
  http://localhost:3000

- Liste des pays :  
  http://localhost:3000/countries

- (Optionnel) Export CSV :  
  http://localhost:3000/export.csv


## Bonnes pratiques appliquÃ©es

-  utilisation dâ€™un navigateur **headless**
-  scraping limitÃ© et responsable
-  cache local pour Ã©viter les appels inutiles
-  sÃ©paration claire des responsabilitÃ©s :
  - scraping
  - nettoyage
  - fusion
  - export
  - affichage
-  `.gitignore` pour Ã©viter de versionner :
  - `node_modules/`
  - `.idea/`
  - fichiers temporaires


## Rappel important (scraping)

Le scraping est rÃ©alisÃ© :
- uniquement sur des pages **publiques**,
- sans authentification,
- Ã  des fins **strictement pÃ©dagogiques**.

Il est interdit de :
- contourner des protections,
- scraper des donnÃ©es personnelles,
- scraper des sites interdisant explicitement le scraping.


## Licence

Ce projet est distribuÃ© sous la licence **Academic Free License v3.0 ([AFL-3.0](https://opensource.org/licenses/AFL-3.0))**.
